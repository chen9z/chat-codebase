#!/usr/bin/env python3
"""
RAG åº”ç”¨è¿è¡Œè„šæœ¬
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ç°åœ¨å¯ä»¥æ­£å¸¸å¯¼å…¥
from src.rag import RAG
from src.model.llm import LLMClient

def main():
    """ä¸»å‡½æ•°"""
    try:
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        if not os.getenv("OPENAI_API_BASE") or not os.getenv("OPENAI_API_KEY"):
            print("âŒ è¯·è®¾ç½® OPENAI_API_BASE å’Œ OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            return
        
        print("ğŸš€ å¯åŠ¨ RAG åº”ç”¨...")
        
        # åˆ›å»º RAG å®ä¾‹ï¼ˆä½¿ç”¨ç®€åŒ–çš„é…ç½®ï¼Œé¿å…ç¼ºå°‘çš„ä¾èµ–ï¼‰
        llm_client = LLMClient(
            base_url=os.getenv("OPENAI_API_BASE"), 
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        app = RAG(
            llm_client=llm_client,
            model="deepseek-chat"
            # æ³¨é‡Šæ‰å¯èƒ½ç¼ºå°‘ä¾èµ–çš„éƒ¨åˆ†
            # embedding_model=JinaCodeEmbeddingModel(),
            # rerank_model=LocalRerankModel()
        )
        
        # ç¤ºä¾‹é¡¹ç›®è·¯å¾„
        project_path = os.path.expanduser("~/workspace/spring-ai")
        if not os.path.exists(project_path):
            project_path = str(project_root)  # ä½¿ç”¨å½“å‰é¡¹ç›®ä½œä¸ºç¤ºä¾‹
        
        project_name = project_path.split("/")[-1]
        
        print(f"ğŸ“ ç´¢å¼•é¡¹ç›®: {project_path}")
        app.index_project(project_path)
        
        print("â“ æŸ¥è¯¢ç¤ºä¾‹...")
        response = app.query(project_name, "è¿™ä¸ªé¡¹ç›®æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ")
        
        print("ğŸ“ å“åº”:")
        for chunk in response:
            print(chunk, end='', flush=True)
        print()
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("ğŸ’¡ æç¤º: æŸäº›ä¾èµ–å¯èƒ½æœªå®‰è£…ï¼Œè¯·æ£€æŸ¥ pyproject.toml")
    except Exception as e:
        print(f"âŒ è¿è¡Œé”™è¯¯: {e}")

if __name__ == "__main__":
    main()
