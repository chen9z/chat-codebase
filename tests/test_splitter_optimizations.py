#!/usr/bin/env python3
"""
æµ‹è¯•åˆ†ç‰‡é€»è¾‘ä¼˜åŒ–åŠŸèƒ½
éªŒè¯ç¼“å­˜ã€é…ç½®åŒ–ã€å¤æ‚åº¦è¯„åˆ†ç­‰æ–°åŠŸèƒ½
"""

import tempfile
import os
import sys
import time
from pathlib import Path

# Add the project root to Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.data.splitter import (
    SplitterConfig, 
    get_splitter_parser, 
    CodeSplitter,
    DefaultSplitter,
    get_file_hash,
    _content_hash_cache,
    _parser_cache
)

# æµ‹è¯•ç”¨çš„Pythonä»£ç ç¤ºä¾‹
PYTHON_CODE_COMPLEX = '''
import os
import sys
from typing import List, Dict, Optional

# è¿™æ˜¯ä¸€ä¸ªç®€å•çš„è®¡ç®—å™¨ç±»ç¤ºä¾‹
class Calculator:
    """
    ä¸€ä¸ªåŠŸèƒ½ä¸°å¯Œçš„è®¡ç®—å™¨ç±»
    æ”¯æŒåŸºæœ¬çš„æ•°å­¦è¿ç®—å’Œé«˜çº§åŠŸèƒ½
    """
    
    def __init__(self):
        self.history: List[str] = []
        self.memory: float = 0.0
        
    def add(self, a: float, b: float) -> float:
        """åŠ æ³•è¿ç®—"""
        result = a + b
        self.history.append(f"{a} + {b} = {result}")
        return result
    
    def subtract(self, a: float, b: float) -> float:
        """å‡æ³•è¿ç®—"""
        result = a - b
        self.history.append(f"{a} - {b} = {result}")
        return result
        
    def multiply(self, a: float, b: float) -> float:
        """ä¹˜æ³•è¿ç®—"""
        result = a * b
        self.history.append(f"{a} * {b} = {result}")
        return result
        
    def divide(self, a: float, b: float) -> float:
        """
        é™¤æ³•è¿ç®—
        åŒ…å«é”™è¯¯å¤„ç†
        """
        if b == 0:
            raise ValueError("Cannot divide by zero")
        result = a / b
        self.history.append(f"{a} / {b} = {result}")
        return result
    
    def complex_calculation(self, numbers: List[float]) -> Dict[str, float]:
        """
        å¤æ‚è®¡ç®—å‡½æ•°
        åŒ…å«å¤šç§æ§åˆ¶æµå’ŒåµŒå¥—ç»“æ„
        """
        results = {}
        
        # è®¡ç®—æ€»å’Œ
        total = 0
        for num in numbers:
            total += num
        results['sum'] = total
        
        # è®¡ç®—å¹³å‡å€¼
        if len(numbers) > 0:
            results['average'] = total / len(numbers)
        else:
            results['average'] = 0
            
        # æŸ¥æ‰¾æœ€å¤§å€¼å’Œæœ€å°å€¼
        if numbers:
            max_val = numbers[0]
            min_val = numbers[0]
            
            for num in numbers[1:]:
                if num > max_val:
                    max_val = num
                elif num < min_val:
                    min_val = num
                    
            results['max'] = max_val
            results['min'] = min_val
            
            # å¤æ‚çš„æ¡ä»¶é€»è¾‘
            try:
                if max_val > 100:
                    if min_val < 0:
                        results['category'] = 'mixed_extreme'
                    else:
                        results['category'] = 'large_positive'
                elif min_val < -100:
                    results['category'] = 'large_negative'
                else:
                    results['category'] = 'moderate'
            except Exception as e:
                results['error'] = str(e)
        
        return results
    
    def get_history(self) -> List[str]:
        """è·å–è®¡ç®—å†å²"""
        return self.history.copy()
    
    def clear_history(self):
        """æ¸…ç©ºå†å²è®°å½•"""
        self.history.clear()

# ç‹¬ç«‹å‡½æ•°
def utility_function(x: int, y: int) -> int:
    """ä¸€ä¸ªç®€å•çš„å·¥å…·å‡½æ•°"""
    return x * y + x - y

def another_simple_function():
    """å¦ä¸€ä¸ªç®€å•å‡½æ•°"""
    print("Hello, World!")

# å…¨å±€å˜é‡
GLOBAL_CONSTANT = 42
global_var = "test"
'''

def test_configuration_system():
    """æµ‹è¯•é…ç½®ç³»ç»Ÿ"""
    print("=" * 60)
    print("æµ‹è¯•é…ç½®ç³»ç»Ÿ")
    print("=" * 60)
    
    # åˆ›å»ºä¸åŒçš„é…ç½®
    configs = {
        "é»˜è®¤é…ç½®": SplitterConfig(),
        "å°å—é…ç½®": SplitterConfig(
            chunk_size=1000,
            min_semantic_chunk_size=50,
            high_priority_independence_ratio=0.2
        ),
        "å¤§å—é…ç½®": SplitterConfig(
            chunk_size=4000,
            min_semantic_chunk_size=500,
            high_priority_independence_ratio=0.5
        ),
        "ä¸¥æ ¼æ³¨é‡Šå…³è”": SplitterConfig(
            max_comment_distance=100,
            max_comment_lines_gap=1
        )
    }
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        f.write(PYTHON_CODE_COMPLEX)
        temp_file = f.name
    
    try:
        for config_name, config in configs.items():
            print(f"\n--- {config_name} ---")
            splitter = get_splitter_parser(temp_file, config=config)
            documents = splitter.split(temp_file, PYTHON_CODE_COMPLEX)
            
            print(f"ç”Ÿæˆå—æ•°: {len(documents)}")
            print(f"å¹³å‡å—å¤§å°: {sum(len(doc.content) for doc in documents) / len(documents):.0f} å­—ç¬¦")
            
            # æ˜¾ç¤ºè¯­ä¹‰ä¿¡æ¯
            for i, doc in enumerate(documents[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                semantic_info = doc.semantic_info
                print(f"  å— {i+1}: ç±»å‹={semantic_info.get('chunk_types', [])}, "
                      f"å¤æ‚åº¦={semantic_info.get('complexity_scores', [])}")
    
    finally:
        os.unlink(temp_file)

def test_caching_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç¼“å­˜æ€§èƒ½")
    print("=" * 60)
    
    # æ¸…é™¤ç¼“å­˜
    _content_hash_cache.clear()
    _parser_cache.clear()
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        f.write(PYTHON_CODE_COMPLEX)
        temp_file = f.name
    
    try:
        # ç¬¬ä¸€æ¬¡è§£æï¼ˆæ— ç¼“å­˜ï¼‰
        start_time = time.time()
        splitter1 = get_splitter_parser(temp_file)
        documents1 = splitter1.split(temp_file, PYTHON_CODE_COMPLEX)
        first_run_time = time.time() - start_time
        
        # ç¬¬äºŒæ¬¡è§£æï¼ˆæœ‰ç¼“å­˜ï¼‰
        start_time = time.time()
        splitter2 = get_splitter_parser(temp_file)
        documents2 = splitter2.split(temp_file, PYTHON_CODE_COMPLEX)
        second_run_time = time.time() - start_time
        
        print(f"ç¬¬ä¸€æ¬¡è§£ææ—¶é—´: {first_run_time:.4f} ç§’")
        print(f"ç¬¬äºŒæ¬¡è§£ææ—¶é—´: {second_run_time:.4f} ç§’")
        print(f"æ€§èƒ½æå‡: {first_run_time / second_run_time:.2f}x")
        print(f"ç¼“å­˜å‘½ä¸­: {len(_content_hash_cache)} ä¸ªå†…å®¹ç¼“å­˜, {len(_parser_cache)} ä¸ªè§£æå™¨ç¼“å­˜")
        
        # éªŒè¯ç»“æœä¸€è‡´æ€§
        assert len(documents1) == len(documents2)
        for d1, d2 in zip(documents1, documents2):
            assert d1.content == d2.content
        print("âœ… ç¼“å­˜ç»“æœéªŒè¯é€šè¿‡")
    
    finally:
        os.unlink(temp_file)

def test_complexity_scoring():
    """æµ‹è¯•å¤æ‚åº¦è¯„åˆ†"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•å¤æ‚åº¦è¯„åˆ†")
    print("=" * 60)
    
    # åˆ›å»ºä¸åŒå¤æ‚åº¦çš„ä»£ç ç¤ºä¾‹
    test_cases = {
        "ç®€å•å‡½æ•°": '''
def simple_add(a, b):
    return a + b
''',
        "ä¸­ç­‰å¤æ‚åº¦": '''
def moderate_function(numbers):
    total = 0
    for num in numbers:
        if num > 0:
            total += num
    return total
''',
        "é«˜å¤æ‚åº¦": '''
def complex_function(data):
    result = {}
    for item in data:
        try:
            if isinstance(item, dict):
                for key, value in item.items():
                    if key in result:
                        if isinstance(value, list):
                            result[key].extend(value)
                        else:
                            result[key].append(value)
                    else:
                        result[key] = [value] if not isinstance(value, list) else value
            elif isinstance(item, list):
                for subitem in item:
                    if subitem not in result:
                        result[subitem] = 1
                    else:
                        result[subitem] += 1
        except Exception as e:
            continue
    return result
'''
    }
    
    for case_name, code in test_cases.items():
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(code)
            temp_file = f.name
        
        try:
            splitter = get_splitter_parser(temp_file)
            documents = splitter.split(temp_file, code)
            
            if documents and documents[0].semantic_info:
                complexity_scores = documents[0].semantic_info.get('complexity_scores', [])
                avg_complexity = sum(complexity_scores) / len(complexity_scores) if complexity_scores else 0
                print(f"{case_name}: å¤æ‚åº¦è¯„åˆ† = {avg_complexity:.2f}")
            else:
                print(f"{case_name}: æ— æ³•è®¡ç®—å¤æ‚åº¦è¯„åˆ†")
        
        finally:
            os.unlink(temp_file)

def test_semantic_information():
    """æµ‹è¯•è¯­ä¹‰ä¿¡æ¯"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•è¯­ä¹‰ä¿¡æ¯")
    print("=" * 60)
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        f.write(PYTHON_CODE_COMPLEX)
        temp_file = f.name
    
    try:
        splitter = get_splitter_parser(temp_file)
        documents = splitter.split(temp_file, PYTHON_CODE_COMPLEX)
        
        print(f"æ€»å…±ç”Ÿæˆ {len(documents)} ä¸ªæ–‡æ¡£å—\n")
        
        for i, doc in enumerate(documents):
            semantic_info = doc.semantic_info
            print(f"æ–‡æ¡£å— {i+1}:")
            print(f"  åˆ†ç‰‡å™¨ç±»å‹: {semantic_info.get('splitter', 'unknown')}")
            print(f"  åŒ…å«çš„è¯­ä¹‰ç±»å‹: {semantic_info.get('chunk_types', [])}")
            print(f"  ä»£ç å—åç§°: {semantic_info.get('chunk_names', [])}")
            print(f"  å¤æ‚åº¦è¯„åˆ†: {semantic_info.get('complexity_scores', [])}")
            print(f"  åŒ…å«æ³¨é‡Š: {semantic_info.get('has_comments', False)}")
            print(f"  è¡ŒèŒƒå›´: {doc.start_line}-{doc.end_line}")
            print(f"  å†…å®¹é•¿åº¦: {len(doc.content)} å­—ç¬¦")
            print()
    
    finally:
        os.unlink(temp_file)

def test_fallback_mechanism():
    """æµ‹è¯•é™çº§æœºåˆ¶"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•é™çº§æœºåˆ¶")
    print("=" * 60)
    
    # æµ‹è¯•ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        f.write("This is a plain text file.\nWith multiple lines.\n")
        temp_file = f.name
    
    try:
        splitter = get_splitter_parser(temp_file)
        assert isinstance(splitter, DefaultSplitter), "åº”è¯¥é™çº§åˆ° DefaultSplitter"
        
        documents = splitter.split(temp_file, "This is a plain text file.\nWith multiple lines.\n")
        assert len(documents) > 0, "åº”è¯¥ç”Ÿæˆè‡³å°‘ä¸€ä¸ªæ–‡æ¡£å—"
        
        # æ£€æŸ¥è¯­ä¹‰ä¿¡æ¯
        if documents[0].semantic_info:
            assert documents[0].semantic_info.get('splitter') == 'default'
            assert documents[0].semantic_info.get('chunk_type') == 'line_based'
        
        print("âœ… é™çº§æœºåˆ¶æµ‹è¯•é€šè¿‡")
    
    finally:
        os.unlink(temp_file)

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ åˆ†ç‰‡é€»è¾‘ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    try:
        test_configuration_system()
        test_caching_performance()
        test_complexity_scoring()
        test_semantic_information()
        test_fallback_mechanism()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("=" * 60)
        
        # æ˜¾ç¤ºæœ€ç»ˆç¼“å­˜çŠ¶æ€
        print(f"æœ€ç»ˆç¼“å­˜çŠ¶æ€:")
        print(f"  å†…å®¹ç¼“å­˜: {len(_content_hash_cache)} é¡¹")
        print(f"  è§£æå™¨ç¼“å­˜: {len(_parser_cache)} é¡¹")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()